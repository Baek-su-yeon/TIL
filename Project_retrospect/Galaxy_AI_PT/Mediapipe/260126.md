# 🧬 현재까지 기술 명세 및 커스텀 로직

본 프로젝트는 최신 AI 비전 기술인 **MediaPipe Tasks API**를 핵심 엔진으로 채택하여, 단순한 제스처 검출을 넘어선 **기하학적 분석 기반의 사용자 제스처 파악**을 목표로 합니다.

## 1. 프레임워크의 진화: Solutions에서 Tasks API로
* **전환 배경**: 기존의 `mp.solutions` 방식은 유지보수가 중단될 예정이며, 최신 **MediaPipe Tasks API**는 Android(Kotlin)와 PC(Python) 환경에서 동일한 모델 파일(`.task`)과 추론 로직을 공유할 수 있어 멀티 플랫폼 개발에 최적화되어 있습니다.
* **핵심 이점**: 
    * 비동기 스트리밍(`LIVE_STREAM`, `VIDEO` 모드) 지원을 통한 저지연 추론 구현

---

## 2. Gesture Recognizer: 제스처 인식 및 하이브리드 판정

단순히 모델이 제공하는 라벨(Label)에 의존하지 않고, **랜드마크 좌표 기반의 2차 수학 연산**을 결합하여 인식 정확도를 극대적으로 높였습니다.

### 🥢 젓가락(Chopsticks) 판정 로직
* **기본 라벨**: `Victory` (검지와 중지를 편 상태).
* **2차 검증**: 검지 끝(Index Tip, 8번)과 중지 끝(Middle Tip, 12번)의 유클리드 거리를 계산합니다.
* **판정 공식**: 
  $$\text{dist} = \sqrt{(x_8-x_{12})^2 + (y_8-y_{12})^2}$$
  두 손가락 사이의 거리가 임계값($\text{distThreshold} = 0.05f$)보다 작을 때만 **`ID_CHOPSTICKS`**로 최종 확정합니다.

### 🎡 다이얼 회전(Dial Turn) 감지
* **데이터 버퍼**: 5프레임(`frameLen`) 동안의 손목(Wrist, 0번)과 검지 끝(Index Tip, 8번)의 좌표를 저장합니다.
* **회전각 분석**: 버퍼의 첫 프레임과 마지막 프레임 사이의 각도 변화량($\Delta \theta$)이 $30.0^\circ$ 이상일 때 회전 제스처로 인식합니다.

---

## 3. Pose Landmarker: 3중 중첩(Redundancy) 트래킹

장애물이 많은 실제 환경에서 트래킹이 끊기는 문제를 해결하기 위해 **3단계 백업 시스템**을 설계했습니다.

### 🛡️ 3중 중심점(Center Point) 설계
카메라와의 거리나 장애물에 의해 특정 부위가 가려져도 추적을 유지하기 위해 다음 세 지점의 중심을 동시에 관찰합니다:

1.  **Shoulders**: 왼쪽 어깨(11번)와 오른쪽 어깨(12번)의 중심. 가장 안정적인 상체 지표입니다.
2.  **Torso**: 어깨(11, 12)와 엉덩이(23, 24) 네 지점의 중심. 몸통 전체의 움직임을 대변합니다.
3.  **Eyes**: 왼쪽 눈(2번)과 오른쪽 눈(5번)의 중심. 얼굴만 보이는 초근접 상황에서 마지막 보루로 활용합니다.

---

## 4. 데이터 전처리 및 수학적 모델링

### 📍 좌표계의 정규화 및 픽셀 변환
* MediaPipe가 제공하는 $0.0 \sim 1.0$ 사이의 정규화된 좌표(Normalized)를 실제 화면 픽셀 좌표로 변환하여 판정에 사용합니다:
  $X_{\text{pixel}} = X_{\text{norm}} \times \text{Width}$
  $Y_{\text{pixel}} = Y_{\text{norm}} \times \text{Height}$

### ⚡ 실시간 속도(Velocity) 산출
피사체의 이동 속도를 파악하여 하드웨어 제어에 활용하기 위해 다음 공식을 실시간으로 계산합니다:
$$v = \frac{\sqrt{(x_t - x_{t-1})^2 + (y_t - y_{t-1})^2}}{\Delta t}$$

---

## 5. 고급 시스템 아키텍처 및 최적화

### ⚡ 비동기 스트림 및 타임스탬프 관리 (Async Pipeline)
* **비동기 추론**: `detect_async` 및 `recognize_async`를 사용하여 메인 UI 스레드의 병목 현상을 방지했습니다.
* **타임스탬프 동기화**: `timestamp_ms`를 생성하여 추론 요청 시마다 고유 ID로 관리합니다.
* **레이턴시 모니터링**: `request_start_times` 맵을 활용하여 추론 시작과 종료 시점의 차이를 계산, 실시간 AI 연산 지연 시간(ms)을 측정하고 최적화 지표로 활용했습니다.

### 🚀 하드웨어 가속 및 위임(Delegate) 설정
* **GPU 가속**: 모바일 환경과 PC 환경 모두에서 실시간성 확보를 위해 `BaseOptions.Delegate.GPU`를 우선적으로 사용하도록 설정했습니다.
* **리소스 관리**: `close()` 메서드를 명시적으로 호출하여 앱 종료 시 네이티브 라이브러리와 GPU 리소스가 안전하게 해제되도록 설계했습니다.

### 🛡️ 신뢰도 임계값(Confidence Threshold) 튜닝
* **검출 임계값**: `min_hand_detection_confidence` 및 `min_pose_presence_confidence`를 **0.7(Hand)** 및 **0.5(Pose)**로 차등 설정하여, 손 제스처는 정확도를 우선시하고 포즈 트래킹은 끊김 없는 연속성을 우선시하도록 튜닝했습니다.

---

## 6. 프레임 버퍼 및 상태 관리 (State Management)

### 📊 시계열 데이터 스무딩 (Smoothing)
* **데큐(Deque) 기반 버퍼**: `ArrayDeque`(Android) 및 `collections.deque`(Python)를 사용하여 최근 5프레임의 데이터를 유지합니다.
* **최빈값 필터(Majority Vote)**: 버퍼 내에서 가장 많이 등장한 라벨을 선택함으로써 단발성 노이즈(Flickering)를 제거하고 일관된 동작 인식을 보장합니다.

---

## 🚨 트러블슈팅
* **타입 불일치 해결**: Android(Kotlin)와 Python 간의 연산 시 발생할 수 있는 정밀도 차이를 방지하기 위해 모든 좌표 연산 단위를 **`Float`**로 통일했습니다.
* **데이터 노이즈 제거**: 카메라 떨림으로 인한 오인식을 막기 위해 **최빈값 필터(Mode Filter)**를 적용, 5프레임 내에서 가장 빈번하게 검출된 라벨을 최종 결과로 채택합니다.
* **임계값의 정수화**: 화면 3등분 판정 시 실수 값 대신 화면 너비에 기반한 **정수형 픽셀 값**(`w // 3`)을 사용하여 판정의 직관성을 높였습니다.