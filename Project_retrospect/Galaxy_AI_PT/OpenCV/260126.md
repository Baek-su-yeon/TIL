# 🎨 OpenCV 및 시각화 기술 명세

본 프로젝트는 OpenCV를 활용하여 AI 추론 결과를 사용자에게 직관적으로 전달하고, 실제 환경에서의 트래킹 임계값을 시각적으로 검증할 수 있는 인터페이스를 구축했습니다.

## 1. 웹캠 및 이미지 전처리 (Camera Pipeline)
* **프레임 캡처**: `cv2.VideoCapture(0)`를 통해 실시간 웹캠 피드를 수신하며, 시스템 부하를 줄이기 위해 루프 내에서 효율적인 프레임 읽기 작업을 수행합니다.
* **색상 공간 변환**: OpenCV의 기본 BGR 포맷을 MediaPipe Tasks API가 요구하는 RGB 포맷으로 변환(`cv2.COLOR_BGR2RGB`)하여 추론 정확도를 확보했습니다.
* **해상도 대응**: `frame.shape`를 통해 동적으로 `h, w` 값을 추출하여, 다양한 카메라 해상도에서도 시각화 요소들이 비율에 맞게 배치되도록 설계했습니다.

---

## 2. 3중 중심점 멀티 컬러 시각화 (Landmark Drawing)
가려짐에 강한 트래킹을 구현하기 위해 세 가지 부위의 중심점을 서로 다른 색상으로 화면에 표시하여 실시간으로 모니터링합니다.

* **Eyes (눈 중심)**: 파란색(`255, 0, 0`) 원으로 표시. 초근접 상황에서 얼굴 추적 상태를 확인합니다.
* **Shoulders (어깨 중심)**: 초록색(`0, 255, 0`) 원으로 표시. 가장 안정적인 메인 트래킹 포인트입니다.
* **Torso (몸통 중심)**: 빨간색(`0, 0, 255`) 원으로 표시. 몸 전체의 무게 중심 이동을 확인합니다.
* **정규화 좌표 변환**: MediaPipe의 정규화 좌표($0.0 \sim 1.0$)를 실제 픽셀 위치로 복원하기 위해 `int(x * w)`, `int(y * h)` 연산을 적용했습니다.

---

## 3. 화면 3등분 픽셀 가이드라인 (Threshold Visualization)
사용자가 화면 중심을 벗어났는지 판정하기 위해 하드코딩된 비율 대신 실제 픽셀 좌표 기반의 경계선을 구현했습니다.

* **정수형 임계값 설정**: 
    * **Left Limit**: `line_left = w // 3`
    * **Right Limit**: `line_right = (2 * w) // 3`
* **가이드라인 드로잉**: `cv2.line`을 사용하여 화면 좌/우 1/3 지점에 수직 점선을 그려, 트래킹 포인트가 경계를 넘는 순간을 시각적으로 명확히 대조합니다.
* **동적 피드백**: 트래킹 포인트 중 어느 하나라도 경계선을 넘으면 화면 상단의 방향 지시 문구 색상을 변경하여 즉각적인 피드백을 제공합니다.

---

## 4. 실시간 HUD 및 정보 오버레이 (Information Overlay)
추론 결과와 시스템 상태를 실시간으로 화면에 텍스트로 투사합니다.

* **Action ID 표시**: 현재 감지된 제스처나 동작 ID(`ID_CHOPSTICKS`, `ID_DIAL` 등)를 화면 중앙 상단에 강조 표시합니다. 특정 동작 감지 시 텍스트 색상을 반전시켜 인지성을 높였습니다.
* **좌표 데이터 스트리밍**: 각 포인트의 픽셀 좌표($x, y$)와 계산된 방향(`DIR: LEFT/CENTER/RIGHT`)을 실시간으로 화면 좌측 상단에 표시하여 디버깅 편의성을 극대화했습니다.
* **성능 모니터링**: `PerformanceMonitor` 클래스를 연동하여 초당 프레임 수(FPS)와 AI 모델의 연산 레이턴시(ms)를 화면 구석에 상시 노출합니다.

---

## 5. 자원 관리 및 종료 처리
* **리소스 해제**: `cap.release()`와 `cv2.destroyAllWindows()`를 명시적으로 호출하여, 비정상 종료 시에도 카메라 장치 점유가 남지 않도록 안전하게 설계했습니다.
* **키 인터럽트**: `cv2.waitKey(1)`를 활용해 'q' 키 입력 시 즉시 루프를 탈출하고 모든 시스템을 안전하게 셧다운하는 기능을 포함했습니다.